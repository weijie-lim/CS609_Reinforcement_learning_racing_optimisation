{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02c70188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "312ce7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import dill as pickle\n",
    "import random\n",
    "import sqlite3\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d00075",
   "metadata": {},
   "source": [
    "### RADIUS SET TO 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da1f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def actRules(self, state):\n",
    "        return 1\n",
    "    \n",
    "    def actNaively(self):\n",
    "        return 4\n",
    "\n",
    "class Car:\n",
    "    def __init__(self, tyre=\"Intermediate\"):\n",
    "        self.default_tyre = tyre\n",
    "        self.possible_tyres = [\"Ultrasoft\", \"Soft\", \"Intermediate\", \"Fullwet\"]\n",
    "        self.pitstop_time = 23\n",
    "        self.reset()\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.change_tyre(self.default_tyre)\n",
    "    \n",
    "    \n",
    "    def degrade(self, w, r):\n",
    "        if self.tyre == \"Ultrasoft\":\n",
    "            self.condition *= (1 - 0.0050*w - (2500-r)/90000)\n",
    "        elif self.tyre == \"Soft\":\n",
    "            self.condition *= (1 - 0.0051*w - (2500-r)/93000)\n",
    "        elif self.tyre == \"Intermediate\":\n",
    "            self.condition *= (1 - 0.0052*abs(0.5-w) - (2500-r)/95000)\n",
    "        elif self.tyre == \"Fullwet\":\n",
    "            self.condition *= (1 - 0.0053*(1-w) - (2500-r)/97000)\n",
    "        \n",
    "        \n",
    "    def change_tyre(self, new_tyre):\n",
    "        assert new_tyre in self.possible_tyres\n",
    "        self.tyre = new_tyre\n",
    "        self.condition = 1.00\n",
    "    \n",
    "    \n",
    "    def get_velocity(self):\n",
    "        if self.tyre == \"Ultrasoft\":\n",
    "            vel = 80.7*(0.2 + 0.8*self.condition**1.5)\n",
    "        elif self.tyre == \"Soft\":\n",
    "            vel = 80.1*(0.2 + 0.8*self.condition**1.5)\n",
    "        elif self.tyre == \"Intermediate\":\n",
    "            vel = 79.5*(0.2 + 0.8*self.condition**1.5)\n",
    "        elif self.tyre == \"Fullwet\":\n",
    "            vel = 79.0*(0.2 + 0.8*self.condition**1.5)\n",
    "        return vel\n",
    "\n",
    "    \n",
    "class Track:\n",
    "    def __init__(self, car=Car()):\n",
    "        # self.radius and self.cur_weather are defined in self.reset()\n",
    "        self.total_laps = 162\n",
    "        self.car = car\n",
    "        self.possible_weather = [\"Dry\", \"20% Wet\", \"40% Wet\", \"60% Wet\", \"80% Wet\", \"100% Wet\"]\n",
    "        self.wetness = {\n",
    "            \"Dry\": 0.00, \"20% Wet\": 0.20, \"40% Wet\": 0.40, \"60% Wet\": 0.60, \"80% Wet\": 0.80, \"100% Wet\": 1.00\n",
    "        }\n",
    "        self.p_transition = {\n",
    "            \"Dry\": {\n",
    "                \"Dry\": 0.987, \"20% Wet\": 0.013, \"40% Wet\": 0.000, \"60% Wet\": 0.000, \"80% Wet\": 0.000, \"100% Wet\": 0.000\n",
    "            },\n",
    "            \"20% Wet\": {\n",
    "                \"Dry\": 0.012, \"20% Wet\": 0.975, \"40% Wet\": 0.013, \"60% Wet\": 0.000, \"80% Wet\": 0.000, \"100% Wet\": 0.000\n",
    "            },\n",
    "            \"40% Wet\": {\n",
    "                \"Dry\": 0.000, \"20% Wet\": 0.012, \"40% Wet\": 0.975, \"60% Wet\": 0.013, \"80% Wet\": 0.000, \"100% Wet\": 0.000\n",
    "            },\n",
    "            \"60% Wet\": {\n",
    "                \"Dry\": 0.000, \"20% Wet\": 0.000, \"40% Wet\": 0.012, \"60% Wet\": 0.975, \"80% Wet\": 0.013, \"100% Wet\": 0.000\n",
    "            },\n",
    "            \"80% Wet\": {\n",
    "                \"Dry\": 0.000, \"20% Wet\": 0.000, \"40% Wet\": 0.000, \"60% Wet\": 0.012, \"80% Wet\": 0.975, \"100% Wet\": 0.013\n",
    "            },\n",
    "            \"100% Wet\": {\n",
    "                \"Dry\": 0.000, \"20% Wet\": 0.000, \"40% Wet\": 0.000, \"60% Wet\": 0.000, \"80% Wet\": 0.012, \"100% Wet\": 0.988\n",
    "            }\n",
    "        }\n",
    "        self.reset()\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.radius = np.random.randint(600,1201)\n",
    "        # self.radius = 900\n",
    "        self.cur_weather = np.random.choice(self.possible_weather)\n",
    "        self.is_done = False\n",
    "        self.pitstop = False\n",
    "        self.laps_cleared = 0\n",
    "        self.car.reset()\n",
    "        return self._get_state()\n",
    "    \n",
    "    \n",
    "    def _get_state(self):\n",
    "        return [self.car.tyre, self.car.condition, self.cur_weather, self.radius, self.laps_cleared]\n",
    "        \n",
    "    \n",
    "    def transition(self, action=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            action (int):\n",
    "                0. Make a pitstop and fit new ‘Ultrasoft’ tyres\n",
    "                1. Make a pitstop and fit new ‘Soft’ tyres\n",
    "                2. Make a pitstop and fit new ‘Intermediate’ tyres\n",
    "                3. Make a pitstop and fit new ‘Fullwet’ tyres\n",
    "                4. Continue the next lap without changing tyres\n",
    "        \"\"\"\n",
    "        ## Pitstop time will be added on the first eight of the subsequent lap\n",
    "        time_taken = 0\n",
    "        if self.laps_cleared == int(self.laps_cleared):\n",
    "            if self.pitstop:\n",
    "                self.car.change_tyre(self.committed_tyre)\n",
    "                time_taken += self.car.pitstop_time\n",
    "                self.pitstop = False\n",
    "        \n",
    "        ## The environment is coded such that only an action taken at the start of the three-quarters mark of each lap matters\n",
    "        if self.laps_cleared - int(self.laps_cleared) == 0.75:\n",
    "            if action < 4:\n",
    "                self.pitstop = True\n",
    "                self.committed_tyre = self.car.possible_tyres[action]\n",
    "            else:\n",
    "                self.pitstop = False\n",
    "        \n",
    "        self.cur_weather = np.random.choice(\n",
    "            self.possible_weather, p=list(self.p_transition[self.cur_weather].values())\n",
    "        )\n",
    "        # we assume that degration happens only after a car has travelled the one-eighth lap\n",
    "        velocity = self.car.get_velocity()\n",
    "        time_taken += (2*np.pi*self.radius/8) / velocity\n",
    "        reward = 0 - time_taken\n",
    "        self.car.degrade(\n",
    "            w=self.wetness[self.cur_weather], r=self.radius\n",
    "        )\n",
    "        self.laps_cleared += 0.125\n",
    "        \n",
    "        if self.laps_cleared == self.total_laps:\n",
    "            self.is_done = True\n",
    "        \n",
    "        next_state = self._get_state()\n",
    "        return reward, next_state, self.is_done, velocity\n",
    "    \n",
    "    def step(self, action):\n",
    "        return self.transition(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aba4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_car = Car()\n",
    "env = Track(new_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19eade91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDLambdaAgent:\n",
    "    def __init__(self, epsilon=0.1, epsilon_decay=0.995, alpha=0.1,\n",
    "                  gamma=0.99, td_lambda=0, n_actions=5,\n",
    "                    no_change_after_lap=150, state_space_discretization=100):\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.Q = defaultdict(lambda: np.zeros(self.n_actions))\n",
    "        self.E = defaultdict(lambda: np.zeros(self.n_actions))  # Eligibility traces\n",
    "        self.n_actions = n_actions\n",
    "        self.state_space_discretization = state_space_discretization\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.no_change_after_lap = no_change_after_lap\n",
    "        self.td_lambda = td_lambda\n",
    "        \n",
    "    def _discretize_state(self, state):\n",
    "        tyre, condition, weather, radius, laps_cleared = state\n",
    "        condition = int(condition * self.state_space_discretization)\n",
    "        \n",
    "        # Discretizing the radius as well by rounding to nearest hundred\n",
    "        radius = round(radius, -2)\n",
    "        return (tyre, condition, weather, radius, laps_cleared)\n",
    "    \n",
    "    def act(self, state):\n",
    "        state = self._discretize_state(state)\n",
    "        _, _, _, _, laps_cleared = state\n",
    "        \n",
    "        if np.random.rand() < self.epsilon:\n",
    "            if laps_cleared >= self.no_change_after_lap:\n",
    "                return 4  # Don't change tires\n",
    "            return np.random.choice(self.n_actions)\n",
    "        else:\n",
    "            action = np.argmax(self.Q.get(state, np.zeros(self.n_actions)))\n",
    "            if laps_cleared >= self.no_change_after_lap and action < 4:\n",
    "                return 4  # Don't change tires\n",
    "            return action\n",
    "        \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        state = self._discretize_state(state)\n",
    "        next_state = self._discretize_state(next_state)\n",
    "        \n",
    "        best_next_action = np.argmax(self.Q[next_state])\n",
    "        td_error = reward + self.gamma * self.Q[next_state][best_next_action] - self.Q[state][action]\n",
    "        \n",
    "        # Increment the eligibility trace for the current state-action pair\n",
    "        self.E[state][action] += 1  \n",
    "        \n",
    "        # Update Q-values for all state-action pairs using TD error and the eligibility traces\n",
    "        for s, actions in self.Q.items():\n",
    "            for a in range(self.n_actions):\n",
    "                self.Q[s][a] += self.alpha * td_error * self.E[s][a]\n",
    "                \n",
    "                # Decay the eligibility trace for the state-action pair\n",
    "                self.E[s][a] *= self.gamma * self.td_lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab3dfc9",
   "metadata": {},
   "source": [
    "retieving best combinations for all td(lambda) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "232291b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KEY PARAMETERS\n",
    "\n",
    "lambda_value = 0.8\n",
    "table_name = f\"gs_results_td_lambda_{lambda_value}\".replace(\".\", \"\")\n",
    "table_names = [f\"gs_results_td_lambda_{l}\".replace(\".\", \"\") for l in [0,0.2,0.4,0.6,0.8,1]]\n",
    "directory = \"e-greedy/agents\" #dir to create\n",
    "gs_db_name = 'e-greedy/grid_search_greedy_r900.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65ab6092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epsilon</th>\n",
       "      <th>epsilon_decay</th>\n",
       "      <th>alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>no_change_after_lap</th>\n",
       "      <th>avg_last_50</th>\n",
       "      <th>min_last_50</th>\n",
       "      <th>max_last_50</th>\n",
       "      <th>eval_avg</th>\n",
       "      <th>overall_avg</th>\n",
       "      <th>lambda_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>160</td>\n",
       "      <td>-16054.310293</td>\n",
       "      <td>-16144.504846</td>\n",
       "      <td>-16002.402039</td>\n",
       "      <td>-15972.868982</td>\n",
       "      <td>-16054.310293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>160</td>\n",
       "      <td>-16087.192161</td>\n",
       "      <td>-16146.337620</td>\n",
       "      <td>-15995.594500</td>\n",
       "      <td>-15930.752616</td>\n",
       "      <td>-16087.192161</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>-16106.523543</td>\n",
       "      <td>-16143.556947</td>\n",
       "      <td>-16028.776164</td>\n",
       "      <td>-15925.539765</td>\n",
       "      <td>-16106.523543</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>-16128.751981</td>\n",
       "      <td>-16156.691405</td>\n",
       "      <td>-16100.812556</td>\n",
       "      <td>-15953.534127</td>\n",
       "      <td>-16128.751981</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>160</td>\n",
       "      <td>-16067.208146</td>\n",
       "      <td>-16155.672758</td>\n",
       "      <td>-15996.008652</td>\n",
       "      <td>-15991.691644</td>\n",
       "      <td>-16067.208146</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160</td>\n",
       "      <td>-16049.145336</td>\n",
       "      <td>-16091.438366</td>\n",
       "      <td>-15991.427960</td>\n",
       "      <td>-15997.234823</td>\n",
       "      <td>-16049.145336</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epsilon  epsilon_decay  alpha  gamma  no_change_after_lap   avg_last_50  \\\n",
       "0     0.20          0.995    0.2    0.6                  160 -16054.310293   \n",
       "0     0.05          0.995    0.9    0.4                  160 -16087.192161   \n",
       "0     0.20          0.995    0.8    1.0                  160 -16106.523543   \n",
       "0     0.20          0.999    0.2    1.0                  160 -16128.751981   \n",
       "0     0.10          0.990    0.6    0.2                  160 -16067.208146   \n",
       "0     0.10          0.990    0.0    0.0                  160 -16049.145336   \n",
       "\n",
       "    min_last_50   max_last_50      eval_avg   overall_avg  lambda_value  \n",
       "0 -16144.504846 -16002.402039 -15972.868982 -16054.310293           0.0  \n",
       "0 -16146.337620 -15995.594500 -15930.752616 -16087.192161           0.2  \n",
       "0 -16143.556947 -16028.776164 -15925.539765 -16106.523543           0.4  \n",
       "0 -16156.691405 -16100.812556 -15953.534127 -16128.751981           0.6  \n",
       "0 -16155.672758 -15996.008652 -15991.691644 -16067.208146           0.8  \n",
       "0 -16091.438366 -15991.427960 -15997.234823 -16049.145336           1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from IPython.display import display\n",
    "\n",
    "#KEY PARAMETERS\n",
    "lambda_values = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "table_names = [f\"gs_results_td_lambda_{l}\".replace(\".\", \"\") for l in lambda_values]\n",
    "directory = \"e-greedy/agents\" #dir to create\n",
    "gs_db_name = 'e-greedy/grid_search_greedy_r900.db'\n",
    "\n",
    "def best_combination_by_eval_avg(table_name, db_name=gs_db_name):\n",
    "    \"\"\"\n",
    "    Fetch the row with the best eval_avg for the given table.\n",
    "\n",
    "    Args:\n",
    "    - table_name (str): Name of the table to query.\n",
    "    - db_name (str): Name of the SQLite database.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A single-row DataFrame containing the best combination by eval_avg.\n",
    "    \"\"\"\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    # Fetch the top row ordered by eval_avg in descending order\n",
    "    df = pd.read_sql_query(f\"SELECT * from {table_name} ORDER BY eval_avg DESC LIMIT 1\", conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "# Create an empty DataFrame to hold all results\n",
    "all_results_df = pd.DataFrame()\n",
    "\n",
    "for t_name, lambda_val in zip(table_names, lambda_values):\n",
    "    result_df = best_combination_by_eval_avg(t_name)\n",
    "    result_df[\"lambda_value\"] = lambda_val\n",
    "    all_results_df = pd.concat([all_results_df, result_df])\n",
    "\n",
    "# Display the combined results\n",
    "display(all_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84837c",
   "metadata": {},
   "source": [
    "track with random radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9163f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a5dff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent for lambda value 0 already exists, skipping...\n",
      "Agent for lambda value 0.2 already exists, skipping...\n",
      "Agent for lambda value 0.4 already exists, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [41:53<00:00, 100.55s/it]\n",
      "6it [41:59, 419.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent for lambda value 0.8 already exists, skipping...\n",
      "Agent for lambda value 1 already exists, skipping...\n",
      "All agents trained and saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from project_helper import *\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "training_episodes = 25\n",
    "\n",
    "def train_agent(td_lambda_value, num_episodes=25):\n",
    "    agent = TDLambdaAgent(td_lambda=td_lambda_value)\n",
    "    episode_rewards = []\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            reward, next_state, done, _ = env.step(action)\n",
    "            agent.update(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "        episode_rewards.append(episode_reward)\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "    return agent\n",
    "\n",
    "new_car = Car()\n",
    "env = Track(new_car)\n",
    "\n",
    "# Check and create directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "best_agents = {}\n",
    "\n",
    "# Assuming table_names is defined somewhere\n",
    "for t_name, lambda_val in tqdm(zip(table_names, lambda_values)):\n",
    "    best_df = best_combination_by_eval_avg(t_name)\n",
    "    try:\n",
    "        best_agent_params = best_df.iloc[0]  # Get the best parameters from the df\n",
    "    except IndexError:\n",
    "        print(f\"No data for {t_name} with lambda value {lambda_val}, skipping...\")\n",
    "        continue  # Skip the rest of the loop for this lambda_val if the line fails\n",
    "\n",
    "    agent_filepath = f\"{directory}/td_lambda_{lambda_val}_agent.pkl\"\n",
    "    if os.path.exists(agent_filepath):\n",
    "        print(f\"Agent for lambda value {lambda_val} already exists, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Train agent\n",
    "    trained_agent = train_agent(lambda_val)\n",
    "    best_agents[lambda_val] = trained_agent\n",
    "    \n",
    "    # Save agent using pickle\n",
    "    with open(agent_filepath, \"wb\") as f:\n",
    "        pickle.dump(trained_agent, f)\n",
    "\n",
    "print(\"All agents trained and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdc2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
